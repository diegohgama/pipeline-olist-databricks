# pipeline-olist-databricks

# ðŸ›’ Pipeline de Engenharia de Dados - Olist E-commerce

Projeto "End-to-End" de Engenharia de Dados construÃ­do para processar dados pÃºblicos do E-commerce Brasileiro (Olist). O objetivo foi construir um Data Lakehouse utilizando a arquitetura Medallion (Bronze, Silver, Gold).

## ðŸ›  Tecnologias Utilizadas
- **Language:** Python (PySpark)
- **Engine:** Azure Databricks (Spark Cluster)
- **Storage:** Databricks File System (DBFS) / Unity Catalog
- **Format:** Delta Lake (Parquet versionado)
- **Orchestration:** Databricks Notebooks

## ðŸ— Arquitetura do Projeto
O pipeline segue a arquitetura **Medallion**:
1.  **Bronze:** IngestÃ£o "Raw" dos dados CSV originais para Delta Lake.
2.  **Silver:** Limpeza, tipagem de dados (Casting), renomeaÃ§Ã£o de colunas e tratamento de nulos.
3.  **Gold:** AgregaÃ§Ãµes de negÃ³cio (Joins e KPIs) para responder perguntas como "Faturamento DiÃ¡rio" e "Top Categorias".

## ðŸ“Š Resultados
> (Aqui vocÃª pode colocar aquele print do grÃ¡fico de vendas que geramos!)
*O grÃ¡fico acima demonstra o pico de vendas identificado na Black Friday de 2017.*

## ðŸš€ Como Executar
1. Clone este repositÃ³rio.
2. FaÃ§a upload dos arquivos da pasta `data` para o seu Databricks Volume.
3. Execute os notebooks na ordem numÃ©rica (01 -> 02 -> 03).
